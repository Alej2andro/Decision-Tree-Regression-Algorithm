# ğŸŒ³ Ãrboles de DecisiÃ³n para RegresiÃ³n

<p align="center">
  <img src="https://st2.depositphotos.com/1121376/6933/i/450/depositphotos_69332881-stock-photo-mighty-oak-tree.jpg" width="500" alt="Decision Tree Regression Algorithm">
  <br>
  <b>Decision Tree Regression Algorithm</b>
</p>

## ğŸ“š Recursos

- ğŸ“„ **Documento interactivo**: [Ver en RPubs](https://rpubs.com/Alej5ndro/DecisionTreesRegression)
- ğŸ“„ **Documento acceso a repositrio**:[Ver en GitHub](https://alej2andro.github.io/Decision-Tree-Regression-Algorithm/)
- ğŸ“– **Referencia**: Breiman et al. (1984) - Classification and Regression Trees

## Â¿De quÃ© se trata este proyecto?

Este proyecto analiza **cÃ³mo funcionan los Ãrboles de DecisiÃ³n** desde sus fundamentos matemÃ¡ticos. No es solo ejecutar cÃ³digo: es entender **por quÃ©** el algoritmo toma cada decisiÃ³n.

Uso el dataset Ames Housing (precios de viviendas) para construir un modelo predictivo, pero el objetivo real es **descomponer la matemÃ¡tica** detrÃ¡s de cada paso.

## ğŸ¯ Lo que aprenderÃ¡s aquÃ­

- CÃ³mo el algoritmo minimiza el error (MSE) en cada divisiÃ³n del Ã¡rbol
- Por quÃ© la poda previene el sobreajuste
- CÃ³mo validar que un modelo realmente funciona (no solo "parece funcionar")
- QuÃ© significan las mÃ©tricas (RÂ², RMSE, MAE)

**FilosofÃ­a**: Entender > Ejecutar. Las matemÃ¡ticas son la base de todo.

## ğŸ“Š Datos

- **Dataset**: Ames Housing (2,930 viviendas en Iowa, 2006-2010)
- **Objetivo**: Predecir precio de venta
- **Variables clave**: Calidad construcciÃ³n, Ã¡rea habitable, tamaÃ±o garage

## ğŸ› ï¸ TecnologÃ­a

- **R + RStudio**: Para anÃ¡lisis estadÃ­stico
- **Quarto**: Para crear documento HTML interactivo
- **LibrerÃ­as**: rpart, ggplot2, caret, corrplot

## ğŸ“ Archivos del proyecto

```
â”œâ”€â”€ Arboles-decisiones-regresion.qmd    # CÃ³digo fuente
â”œâ”€â”€ Arboles-decisiones-regresion.html   # Documento final (abrir en navegador)
â”œâ”€â”€ modelo_arbol_regresion.rds          # Modelo entrenado
â””â”€â”€ README.md                           # Este archivo
```

## ğŸ” Proceso

1. **ExploraciÃ³n de datos**: Â¿QuÃ© tienen los datos? Â¿Hay valores raros?
2. **ConstrucciÃ³n del Ã¡rbol**: Empezar simple, luego optimizar
3. **ValidaciÃ³n cruzada**: Â¿Funciona con datos que no vio antes?
4. **OptimizaciÃ³n**: Probar 81 combinaciones de parÃ¡metros
5. **EvaluaciÃ³n final**: Â¿QuÃ© tan bueno es realmente?

## ğŸ“ˆ Resultados

| Modelo | Error (RMSE) | Varianza Explicada (RÂ²) |
|--------|--------------|-------------------------|
| Baseline (predecir promedio) | $79,060 | 0% |
| **Modelo Final** | **$32,120** | **93%** |

**Mejora**: 59% menos error que simplemente predecir el precio promedio.

**Variables mÃ¡s importantes**:
1. Calidad de construcciÃ³n (36%)
2. Ãrea habitable (28%)
3. TamaÃ±o de garage (15%)

## ğŸš€ CÃ³mo usarlo

**Instalar R y RStudio**, luego:

```r
# Instalar paquetes necesarios
install.packages(c("rpart", "rpart.plot", "caret", "ggplot2", 
                   "corrplot", "dplyr", "knitr", "AmesHousing"))

# Renderizar documento
quarto::quarto_render("Arboles-decisiones-regresion.qmd")
```

O simplemente abre el archivo `.html` en tu navegador.

## ğŸ’¡ Lo que me motiva

> *"No basta con saber ejecutar algoritmos. Hay que entender la matemÃ¡tica que los hace funcionar."*

En Machine Learning es fÃ¡cil copiar cÃ³digo y confiar en que "funciona". Pero **la maestrÃ­a estÃ¡ en el "por quÃ©"**:

- Â¿Por quÃ© este split reduce el error mÃ¡s que otros?
- Â¿Por quÃ© mantener outliers mejora el modelo?
- Â¿CÃ³mo sÃ© si mi modelo es estable o tuvo suerte?

**Las matemÃ¡ticas explican todo. La curiosidad es el motor del aprendizaje.**

## ğŸ“¬ Contacto

**Alejandro Figueroa Rojas**

- LinkedIn: [linkedin.com/in/alejandrofigueroarojas](https://www.linkedin.com/in/alejandrofigueroarojas)
- RPubs: [rpubs.com/Alej5ndro](https://rpubs.com/Alej5ndro)
- Email: alejandro.figueroa.rojas@gmail.com

---

â­ **Si crees que entender es mejor que memorizar, este proyecto es para ti**

ğŸ’¬ **Â¿Dudas? Â¿Ideas? EscrÃ­beme**
